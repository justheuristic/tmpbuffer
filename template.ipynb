{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Шаблон решения\n",
    "* Простой способ разработать своё первое решение и сгенерировать файл на проверку\n",
    "* Дублирует функции из baseline\n",
    "* Следовать ему не обязательно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Прочитаем данные "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame.from_csv(\"./train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_col = [ 'dist','due', 'lat','lon','f_class','s_class','t_class',]\n",
    "X_raw = data[x_col]\n",
    "y = data['burned'].values\n",
    "w = data['weights'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "#вытаскиватель категориальных фичей\n",
    "vectorizer = DictVectorizer(sparse=False,dtype=np.bool)\n",
    "\n",
    "def preprocess_data(X_raw):\n",
    "    \n",
    "    <Как нибудь предобработать данные>\n",
    "    \n",
    "    return <предобработанные данные>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = preprocess_data(X_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поделим на обучение и валидацию\n",
    "* Важно, что мы делим не случайно, а по времени, т.к. тестовые данные по времени дальше обучающих"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Как-нибудь порезать данные\n",
    "Xtr = X[:1000000]\n",
    "Xval = X[1000000:]\n",
    "Ytr = y[:1000000]\n",
    "Yval = y[1000000:]\n",
    "Wtr = w[:1000000]\n",
    "Wval = w[1000000:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = <Как-нибудь обученная модель>\n",
    "model.fit(Xtr,Ytr,sample_weight=Wtr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценим качество"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score,accuracy_score,precision_score,recall_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "\n",
    "for source_i, Xi,Yi,Wi in [\n",
    "                            [\"train\",Xtr,Ytr,Wtr],\n",
    "                            [\"val\",Xval,Yval,Wval]\n",
    "                                ]:\n",
    "    \n",
    "    # Предскажем вероятность сгорания\n",
    "    Yi_pred_proba = model.predict_proba(Xi)[:,1]\n",
    "    \n",
    "    #Поделим предсказание на сгоревшие и не сгоревшие по порогу (0.5)\n",
    "    thr = 0.5\n",
    "    Yi_pred_class = Yi_pred_proba>thr\n",
    "\n",
    "    auc = roc_auc_score(Yi,Yi_pred_proba,sample_weight = Wi)\n",
    "    acc = accuracy_score(Yi,Yi_pred_class,sample_weight = Wi)\n",
    "    prc = precision_score(Yi,Yi_pred_class,sample_weight = Wi)\n",
    "    rcl = recall_score(Yi,Yi_pred_class,sample_weight = Wi)\n",
    "    \n",
    "    print '%s: \\t AUC = %.5f \\t Accuracy = %.5f \\t Precision = %.5f \\t Recall = %.5f'%(source_i, auc, acc,prc,rcl)\n",
    "    \n",
    "    fpr,tpr,_ = roc_curve(Yi,Yi_pred_proba,sample_weight=Wi)\n",
    "    \n",
    "    plt.plot(fpr,tpr,label = source_i)\n",
    "    \n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_forest_feature_importances(rf,feature_names):\n",
    "    importances = rf.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in rf.estimators_],\n",
    "                 axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    # Print the feature ranking\n",
    "    print(\"Feature ranking:\")\n",
    "\n",
    "    for f in range(X.shape[1]):\n",
    "        print(\"%d. %s (%f)\" % (f + 1, feature_names[f], importances[indices[f]]))\n",
    "\n",
    "    # Plot the feature importances of the forest\n",
    "    plt.figure()\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(range(X.shape[1]), importances[indices],\n",
    "           color=\"r\", yerr=std[indices], align=\"center\")\n",
    "    plt.xticks(range(X.shape[1]), indices)\n",
    "    plt.xlim([-1, X.shape[1]])\n",
    "    \n",
    "    plt.yscale(\"log\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_forest_feature_importances(model,X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Отгрузим решение в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_submission(preproc_fun,model,filename=\"submission.csv\",threshold = 0.5):\n",
    "    \n",
    "    data_eval = pd.DataFrame.from_csv(\"./evaluation.handout.csv\")\n",
    "    \n",
    "    \n",
    "    x_col = [ 'dist','due', 'lat','lon','f_class','s_class','t_class',]\n",
    "    X_eval = preproc_fun(data_eval[x_col])\n",
    "    \n",
    "    # Предскажем вероятность сгорания\n",
    "    Y_pred_proba_eval = model.predict_proba(X_eval)[:,1]\n",
    "    \n",
    "    #Поделим предсказание на сгоревшие и не сгоревшие по порогу (thr)\n",
    "    \n",
    "    Y_pred_class_eval = Y_pred_proba_eval>threshold\n",
    "    \n",
    "    \n",
    "    response = pd.DataFrame()\n",
    "    response[\"Y_class\"] = Y_pred_class_eval.astype(int)\n",
    "    response[\"Y_prob\"] = map(\"{0:.5f}\".format,Y_pred_proba_eval)\n",
    "    \n",
    "    \n",
    "    response.to_csv(filename,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generate_submission(preprocess_data,model,\"my_submission.csv\",threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!head my_submission.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
